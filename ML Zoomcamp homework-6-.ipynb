{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Homework\n",
    "\n",
    "The goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n",
    "\n",
    "In this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
    "if you don't want to sign up to Kaggle.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('AB_NYC_2019.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the log tranform to `price`\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = np.log1p(df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.price\n",
    "y_val = df_val.price\n",
    "y_test = df_test.price\n",
    "\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `DictVectorizer` to turn train and validation into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = df_train.to_dict(orient = 'records')\n",
    "val_dict = df_val.to_dict(orient = 'records')\n",
    "\n",
    "dv = DictVectorizer(sparse = False)\n",
    "\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable. \n",
    "\n",
    "* Train a model with `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = dt(max_depth =1)\n",
    "\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 1,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_params(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- room_type=Entire home/apt <= 0.50\n",
      "|   |--- value: [4.29]\n",
      "|--- room_type=Entire home/apt >  0.50\n",
      "|   |--- value: [5.15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(reg, feature_names = dv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `room_type`\n",
    "* `neighbourhood_group`\n",
    "* `number_of_reviews`\n",
    "* `reviews_per_month`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1`  (optional - to make training faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int= []\n",
    "for num in y_train:\n",
    "    num = int(num)\n",
    "    y_train_int.append(num)\n",
    "    \n",
    "y_train_int\n",
    "\n",
    "rf.fit(X_train, y_train_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6194266290920285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.059\n",
    "* 0.259\n",
    "* 0.459\n",
    "* 0.659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10\n",
    "* Set `random_state` to `1`\n",
    "* Evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_estimator: 10, rmse: 0.619\n",
      "num_estimator: 20, rmse: 0.58\n",
      "num_estimator: 30, rmse: 0.561\n",
      "num_estimator: 40, rmse: 0.554\n",
      "num_estimator: 50, rmse: 0.557\n",
      "num_estimator: 60, rmse: 0.557\n",
      "num_estimator: 70, rmse: 0.552\n",
      "num_estimator: 80, rmse: 0.553\n",
      "num_estimator: 90, rmse: 0.552\n",
      "num_estimator: 100, rmse: 0.548\n",
      "num_estimator: 110, rmse: 0.549\n",
      "num_estimator: 120, rmse: 0.547\n",
      "num_estimator: 130, rmse: 0.548\n",
      "num_estimator: 140, rmse: 0.549\n",
      "num_estimator: 150, rmse: 0.545\n",
      "num_estimator: 160, rmse: 0.546\n",
      "num_estimator: 170, rmse: 0.547\n",
      "num_estimator: 180, rmse: 0.546\n",
      "num_estimator: 190, rmse: 0.544\n"
     ]
    }
   ],
   "source": [
    "rmse_vals=[]\n",
    "\n",
    "n_estimators = [10, 20, 30, 40, 50, 60,\n",
    "                70, 80, 90, 100, 110,\n",
    "                120, 130, 140, 150,\n",
    "                160, 170, 180, 190,]\n",
    "\n",
    "for num in n_estimators:\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=num, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train_int)\n",
    "    \n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse_val =rmse(y_val, y_pred)\n",
    "    \n",
    "    print(f'num_estimator: {num}, rmse: {rmse_val.round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 50\n",
    "- 70\n",
    "- 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [10, 15, 20, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " n_estimators = [10, 20, 30, 40, 50, 60,\n",
    "                70, 80, 90, 100, 110,\n",
    "                120, 130, 140, 150,\n",
    "                160, 170, 180, 190,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 10__________-\n",
      "num_estimator:10 rmse:0.503\n",
      "num_estimator:20 rmse:0.5\n",
      "num_estimator:30 rmse:0.492\n",
      "num_estimator:40 rmse:0.494\n",
      "num_estimator:50 rmse:0.493\n",
      "num_estimator:60 rmse:0.495\n",
      "num_estimator:70 rmse:0.495\n",
      "num_estimator:80 rmse:0.497\n",
      "num_estimator:90 rmse:0.495\n",
      "num_estimator:100 rmse:0.493\n",
      "num_estimator:110 rmse:0.492\n",
      "num_estimator:120 rmse:0.494\n",
      "num_estimator:130 rmse:0.493\n",
      "num_estimator:140 rmse:0.493\n",
      "num_estimator:150 rmse:0.494\n",
      "num_estimator:160 rmse:0.493\n",
      "num_estimator:170 rmse:0.493\n",
      "num_estimator:180 rmse:0.495\n",
      "num_estimator:190 rmse:0.495\n",
      "depth: 10 end _ _ _ __ _ _ _ _ _ -\n",
      "\n",
      "depth: 15__________-\n",
      "num_estimator:10 rmse:0.542\n",
      "num_estimator:20 rmse:0.521\n",
      "num_estimator:30 rmse:0.515\n",
      "num_estimator:40 rmse:0.514\n",
      "num_estimator:50 rmse:0.514\n",
      "num_estimator:60 rmse:0.513\n",
      "num_estimator:70 rmse:0.511\n",
      "num_estimator:80 rmse:0.512\n",
      "num_estimator:90 rmse:0.511\n",
      "num_estimator:100 rmse:0.511\n",
      "num_estimator:110 rmse:0.508\n",
      "num_estimator:120 rmse:0.509\n",
      "num_estimator:130 rmse:0.511\n",
      "num_estimator:140 rmse:0.511\n",
      "num_estimator:150 rmse:0.508\n",
      "num_estimator:160 rmse:0.508\n",
      "num_estimator:170 rmse:0.509\n",
      "num_estimator:180 rmse:0.511\n",
      "num_estimator:190 rmse:0.51\n",
      "depth: 15 end _ _ _ __ _ _ _ _ _ -\n",
      "\n",
      "depth: 20__________-\n",
      "num_estimator:10 rmse:0.563\n",
      "num_estimator:20 rmse:0.542\n",
      "num_estimator:30 rmse:0.538\n",
      "num_estimator:40 rmse:0.534\n",
      "num_estimator:50 rmse:0.53\n",
      "num_estimator:60 rmse:0.533\n",
      "num_estimator:70 rmse:0.534\n",
      "num_estimator:80 rmse:0.533\n",
      "num_estimator:90 rmse:0.53\n",
      "num_estimator:100 rmse:0.53\n",
      "num_estimator:110 rmse:0.53\n",
      "num_estimator:120 rmse:0.53\n",
      "num_estimator:130 rmse:0.528\n",
      "num_estimator:140 rmse:0.528\n",
      "num_estimator:150 rmse:0.527\n",
      "num_estimator:160 rmse:0.528\n",
      "num_estimator:170 rmse:0.526\n",
      "num_estimator:180 rmse:0.526\n",
      "num_estimator:190 rmse:0.528\n",
      "depth: 20 end _ _ _ __ _ _ _ _ _ -\n",
      "\n",
      "depth: 25__________-\n",
      "num_estimator:10 rmse:0.594\n",
      "num_estimator:20 rmse:0.558\n",
      "num_estimator:30 rmse:0.555\n",
      "num_estimator:40 rmse:0.55\n",
      "num_estimator:50 rmse:0.545\n",
      "num_estimator:60 rmse:0.543\n",
      "num_estimator:70 rmse:0.541\n",
      "num_estimator:80 rmse:0.54\n",
      "num_estimator:90 rmse:0.537\n",
      "num_estimator:100 rmse:0.535\n",
      "num_estimator:110 rmse:0.539\n",
      "num_estimator:120 rmse:0.537\n",
      "num_estimator:130 rmse:0.535\n",
      "num_estimator:140 rmse:0.535\n",
      "num_estimator:150 rmse:0.536\n",
      "num_estimator:160 rmse:0.535\n",
      "num_estimator:170 rmse:0.537\n",
      "num_estimator:180 rmse:0.538\n",
      "num_estimator:190 rmse:0.537\n",
      "depth: 25 end _ _ _ __ _ _ _ _ _ -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in max_depth:\n",
    "    print(f'depth: {depth}__________-')     \n",
    "    for n_estimator in n_estimators:\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=n_estimator, random_state=1,max_depth =depth,  n_jobs=-1)\n",
    "        rf.fit(X_train, y_train_int)\n",
    "        \n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse_val = rmse(y_val, y_pred)\n",
    "        \n",
    "    \n",
    "        print(f'num_estimator:{n_estimator} rmse:{rmse_val.round(3)}')\n",
    "        \n",
    "    print(f'depth: {depth} end _ _ _ __ _ _ _ _ _ -\\n')\n",
    "           \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=20, n_estimators=10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most important feature? \n",
    "\n",
    "* `neighbourhood_group=Manhattan`\n",
    "* `room_type=Entire home/apt`\t\n",
    "* `longitude`\n",
    "* `latitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=10, random_state=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['neighbourhood_group', 'latitude', 'longitude', 'room_type',\n",
       "       'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
       "       'calculated_host_listings_count', 'availability_365'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: neighbourhood_group, importance: 0.10815028296010229\n",
      "feature: latitude, importance: 0.05461524475357107\n",
      "feature: longitude, importance: 0.17587752485411118\n",
      "feature: room_type, importance: 0.1893043749397983\n",
      "feature: minimum_nights, importance: 0.0719037134634464\n",
      "feature: number_of_reviews, importance: 0.0019921716712088247\n",
      "feature: reviews_per_month, importance: 0.00700831325014685\n",
      "feature: calculated_host_listings_count, importance: 0.02502500107846909\n",
      "feature: availability_365, importance: 0.004808648093854574\n"
     ]
    }
   ],
   "source": [
    "for feat, importance in zip(df_train.columns, rf.feature_importances_):\n",
    "    print ('feature: {f}, importance: {i}'.format(f=feat, i=importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/zach/anaconda3/envs/ml-zoomcamp/lib/python3.8/site-packages (1.4.2)\r\n",
      "Requirement already satisfied: numpy in /home/zach/anaconda3/envs/ml-zoomcamp/lib/python3.8/site-packages (from xgboost) (1.19.5)\r\n",
      "Requirement already satisfied: scipy in /home/zach/anaconda3/envs/ml-zoomcamp/lib/python3.8/site-packages (from xgboost) (1.7.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change `eta` first to `0.1` and then to `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.get_feature_names()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names = features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'), (dval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.02752\tval-rmse:3.02415\n",
      "[5]\ttrain-rmse:0.67490\tval-rmse:0.67752\n",
      "[10]\ttrain-rmse:0.43912\tval-rmse:0.44981\n",
      "[15]\ttrain-rmse:0.42259\tval-rmse:0.43827\n",
      "[20]\ttrain-rmse:0.41716\tval-rmse:0.43691\n",
      "[25]\ttrain-rmse:0.41365\tval-rmse:0.43621\n",
      "[30]\ttrain-rmse:0.40712\tval-rmse:0.43543\n",
      "[35]\ttrain-rmse:0.40444\tval-rmse:0.43510\n",
      "[40]\ttrain-rmse:0.40103\tval-rmse:0.43466\n",
      "[45]\ttrain-rmse:0.39723\tval-rmse:0.43371\n",
      "[50]\ttrain-rmse:0.39446\tval-rmse:0.43384\n",
      "[55]\ttrain-rmse:0.39129\tval-rmse:0.43378\n",
      "[60]\ttrain-rmse:0.38743\tval-rmse:0.43404\n",
      "[65]\ttrain-rmse:0.38421\tval-rmse:0.43450\n",
      "[70]\ttrain-rmse:0.38117\tval-rmse:0.43467\n",
      "[75]\ttrain-rmse:0.37801\tval-rmse:0.43489\n",
      "[80]\ttrain-rmse:0.37668\tval-rmse:0.43526\n",
      "[85]\ttrain-rmse:0.37259\tval-rmse:0.43537\n",
      "[90]\ttrain-rmse:0.36998\tval-rmse:0.43539\n",
      "[95]\ttrain-rmse:0.36742\tval-rmse:0.43579\n",
      "[100]\ttrain-rmse:0.36401\tval-rmse:0.43628\n",
      "[105]\ttrain-rmse:0.36181\tval-rmse:0.43673\n",
      "[110]\ttrain-rmse:0.35892\tval-rmse:0.43677\n",
      "[115]\ttrain-rmse:0.35588\tval-rmse:0.43718\n",
      "[120]\ttrain-rmse:0.35213\tval-rmse:0.43704\n",
      "[125]\ttrain-rmse:0.35099\tval-rmse:0.43713\n",
      "[130]\ttrain-rmse:0.34903\tval-rmse:0.43750\n",
      "[135]\ttrain-rmse:0.34724\tval-rmse:0.43767\n",
      "[140]\ttrain-rmse:0.34416\tval-rmse:0.43809\n",
      "[145]\ttrain-rmse:0.34095\tval-rmse:0.43876\n",
      "[150]\ttrain-rmse:0.33934\tval-rmse:0.43919\n",
      "[155]\ttrain-rmse:0.33715\tval-rmse:0.43933\n",
      "[160]\ttrain-rmse:0.33602\tval-rmse:0.43931\n",
      "[165]\ttrain-rmse:0.33430\tval-rmse:0.43944\n",
      "[170]\ttrain-rmse:0.33209\tval-rmse:0.44011\n",
      "[175]\ttrain-rmse:0.32915\tval-rmse:0.44050\n",
      "[180]\ttrain-rmse:0.32701\tval-rmse:0.44080\n",
      "[185]\ttrain-rmse:0.32510\tval-rmse:0.44119\n",
      "[190]\ttrain-rmse:0.32372\tval-rmse:0.44127\n",
      "[195]\ttrain-rmse:0.32194\tval-rmse:0.44130\n",
      "[199]\ttrain-rmse:0.32040\tval-rmse:0.44131\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "        \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=200, evals=watchlist,\n",
    "                 verbose_eval=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.87217\tval-rmse:3.86889\n",
      "[5]\ttrain-rmse:2.31905\tval-rmse:2.31692\n",
      "[10]\ttrain-rmse:1.41910\tval-rmse:1.41786\n",
      "[15]\ttrain-rmse:0.91299\tval-rmse:0.91348\n",
      "[20]\ttrain-rmse:0.64528\tval-rmse:0.64883\n",
      "[25]\ttrain-rmse:0.51733\tval-rmse:0.52364\n",
      "[30]\ttrain-rmse:0.46186\tval-rmse:0.47101\n",
      "[35]\ttrain-rmse:0.43843\tval-rmse:0.44997\n",
      "[40]\ttrain-rmse:0.42770\tval-rmse:0.44150\n",
      "[45]\ttrain-rmse:0.42222\tval-rmse:0.43795\n",
      "[50]\ttrain-rmse:0.41868\tval-rmse:0.43589\n",
      "[55]\ttrain-rmse:0.41644\tval-rmse:0.43515\n",
      "[60]\ttrain-rmse:0.41432\tval-rmse:0.43460\n",
      "[65]\ttrain-rmse:0.41226\tval-rmse:0.43400\n",
      "[70]\ttrain-rmse:0.41059\tval-rmse:0.43361\n",
      "[75]\ttrain-rmse:0.40876\tval-rmse:0.43336\n",
      "[80]\ttrain-rmse:0.40747\tval-rmse:0.43306\n",
      "[85]\ttrain-rmse:0.40626\tval-rmse:0.43299\n",
      "[90]\ttrain-rmse:0.40478\tval-rmse:0.43280\n",
      "[95]\ttrain-rmse:0.40406\tval-rmse:0.43272\n",
      "[100]\ttrain-rmse:0.40260\tval-rmse:0.43242\n",
      "[105]\ttrain-rmse:0.40162\tval-rmse:0.43244\n",
      "[110]\ttrain-rmse:0.40016\tval-rmse:0.43213\n",
      "[115]\ttrain-rmse:0.39916\tval-rmse:0.43197\n",
      "[120]\ttrain-rmse:0.39794\tval-rmse:0.43161\n",
      "[125]\ttrain-rmse:0.39713\tval-rmse:0.43160\n",
      "[130]\ttrain-rmse:0.39578\tval-rmse:0.43142\n",
      "[135]\ttrain-rmse:0.39499\tval-rmse:0.43140\n",
      "[140]\ttrain-rmse:0.39406\tval-rmse:0.43125\n",
      "[145]\ttrain-rmse:0.39289\tval-rmse:0.43095\n",
      "[150]\ttrain-rmse:0.39188\tval-rmse:0.43083\n",
      "[155]\ttrain-rmse:0.39060\tval-rmse:0.43073\n",
      "[160]\ttrain-rmse:0.38907\tval-rmse:0.43049\n",
      "[165]\ttrain-rmse:0.38773\tval-rmse:0.43044\n",
      "[170]\ttrain-rmse:0.38649\tval-rmse:0.43024\n",
      "[175]\ttrain-rmse:0.38591\tval-rmse:0.43025\n",
      "[180]\ttrain-rmse:0.38468\tval-rmse:0.43030\n",
      "[185]\ttrain-rmse:0.38377\tval-rmse:0.43026\n",
      "[190]\ttrain-rmse:0.38286\tval-rmse:0.43021\n",
      "[195]\ttrain-rmse:0.38198\tval-rmse:0.43011\n",
      "[199]\ttrain-rmse:0.38160\tval-rmse:0.43010\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "        \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=200, evals=watchlist,\n",
    "                 verbose_eval=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.25336\tval-rmse:4.25010\n",
      "[5]\ttrain-rmse:4.04779\tval-rmse:4.04454\n",
      "[10]\ttrain-rmse:3.85242\tval-rmse:3.84921\n",
      "[15]\ttrain-rmse:3.66674\tval-rmse:3.66359\n",
      "[20]\ttrain-rmse:3.49030\tval-rmse:3.48719\n",
      "[25]\ttrain-rmse:3.32263\tval-rmse:3.31956\n",
      "[30]\ttrain-rmse:3.16332\tval-rmse:3.16029\n",
      "[35]\ttrain-rmse:3.01196\tval-rmse:3.00898\n",
      "[40]\ttrain-rmse:2.86817\tval-rmse:2.86533\n",
      "[45]\ttrain-rmse:2.73158\tval-rmse:2.72884\n",
      "[50]\ttrain-rmse:2.60185\tval-rmse:2.59925\n",
      "[55]\ttrain-rmse:2.47865\tval-rmse:2.47612\n",
      "[60]\ttrain-rmse:2.36167\tval-rmse:2.35927\n",
      "[65]\ttrain-rmse:2.25061\tval-rmse:2.24835\n",
      "[70]\ttrain-rmse:2.14519\tval-rmse:2.14303\n",
      "[75]\ttrain-rmse:2.04514\tval-rmse:2.04311\n",
      "[80]\ttrain-rmse:1.95022\tval-rmse:1.94827\n",
      "[85]\ttrain-rmse:1.86015\tval-rmse:1.85833\n",
      "[90]\ttrain-rmse:1.77472\tval-rmse:1.77302\n",
      "[95]\ttrain-rmse:1.69373\tval-rmse:1.69214\n",
      "[100]\ttrain-rmse:1.61695\tval-rmse:1.61546\n",
      "[105]\ttrain-rmse:1.54419\tval-rmse:1.54280\n",
      "[110]\ttrain-rmse:1.47527\tval-rmse:1.47404\n",
      "[115]\ttrain-rmse:1.41000\tval-rmse:1.40890\n",
      "[120]\ttrain-rmse:1.34820\tval-rmse:1.34725\n",
      "[125]\ttrain-rmse:1.28976\tval-rmse:1.28888\n",
      "[130]\ttrain-rmse:1.23445\tval-rmse:1.23378\n",
      "[135]\ttrain-rmse:1.18218\tval-rmse:1.18167\n",
      "[140]\ttrain-rmse:1.13278\tval-rmse:1.13240\n",
      "[145]\ttrain-rmse:1.08613\tval-rmse:1.08588\n",
      "[150]\ttrain-rmse:1.04212\tval-rmse:1.04201\n",
      "[155]\ttrain-rmse:1.00063\tval-rmse:1.00067\n",
      "[160]\ttrain-rmse:0.96151\tval-rmse:0.96179\n",
      "[165]\ttrain-rmse:0.92468\tval-rmse:0.92517\n",
      "[170]\ttrain-rmse:0.89000\tval-rmse:0.89068\n",
      "[175]\ttrain-rmse:0.85734\tval-rmse:0.85825\n",
      "[180]\ttrain-rmse:0.82670\tval-rmse:0.82783\n",
      "[185]\ttrain-rmse:0.79787\tval-rmse:0.79926\n",
      "[190]\ttrain-rmse:0.77092\tval-rmse:0.77252\n",
      "[195]\ttrain-rmse:0.74555\tval-rmse:0.74745\n",
      "[199]\ttrain-rmse:0.72641\tval-rmse:0.72856\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "        \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=200, evals=watchlist,\n",
    "                 verbose_eval=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: eta: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "\n",
    "Submit your results here: https://forms.gle/wQgFkYE6CtdDed4w8\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "\n",
    "The deadline for submitting is 20 October 2021, 17:00 CET (Wednesday). After that, the form will be closed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
